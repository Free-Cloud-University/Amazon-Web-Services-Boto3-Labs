{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d371bca",
   "metadata": {},
   "source": [
    "# Introduction to Athena and Glue - Free Cloud University\n",
    "\n",
    "**Goal** The purpose of this lab is to expose you to interact with Athena and Glue using Python. By the end of this lab, you should be able to:\n",
    "* Create a data catalog and database with Glue\n",
    "* Create a data crawler with Glue\n",
    "* Query datasets in S3 with Athena\n",
    "\n",
    "Before you begin, ensure that you have Python 3 installed by running the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416cb0a6",
   "metadata": {},
   "source": [
    "Run this code block to ensure that the boto3 library is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059be3db",
   "metadata": {},
   "source": [
    "Run this code block to import the necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e513000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This module is necessary for interacting with AWS\n",
    "import boto3\n",
    "\n",
    "#We will be using these modules to create fake data\n",
    "import time\n",
    "from math import sin, cos\n",
    "import random\n",
    "import csv\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1434226f",
   "metadata": {},
   "source": [
    "Running the code block below will set the region the boto3 library will create the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d877b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will be using US-East-1 as the default region\n",
    "%env AWS_DEFAULT_REGION=us-east-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6510c",
   "metadata": {},
   "source": [
    "Additionally, to complete the lab, you will need to come up with names for the resources. The account ID is accessible on your AWS console. You can name the rest of the resources whatever you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10952f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants for code clarity\n",
    "ACCOUNT_ID = None\n",
    "IAM_GLUE_ROLE_NAME = None\n",
    "S3_BUCKET_NAME = None\n",
    "GLUE_DATABASE = None\n",
    "GLUE_CRAWLER = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80261b9",
   "metadata": {},
   "source": [
    "Additionally, to complete this lab, you will need to run the following code block, which creates a file for you to upload to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f7dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a simple file to upload into S3\n",
    "with open('sin_cos.csv','w') as file_to_write:\n",
    "    csv_to_write = csv.writer(file_to_write)\n",
    "    csv_to_write.writerow(['timestamp','sine','cosine','name'])\n",
    "    for x in range(2000):\n",
    "        current_timestamp = time.time() * 10000000\n",
    "        csv_to_write.writerow([\n",
    "            str(current_timestamp),\n",
    "            sin(current_timestamp),\n",
    "            cos(current_timestamp),\n",
    "            random.choice(['Amanda','Becky','Cindy','Davis'])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b409d61",
   "metadata": {},
   "source": [
    "Finally, before we can interact with all of the AWS resources, we need to create the boto3 clients. \n",
    "\n",
    "**Try It Out Yourself**: Fill in the missing `None` values with your AWS credentials and run the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = {\n",
    "    'aws_access_key_id' : None,\n",
    "    'aws_access_secret_key' : None\n",
    "}\n",
    "\n",
    "athena = boto3.client(\n",
    "    'athena',\n",
    "    aws_access_key_id=creds['aws_access_key_id'],\n",
    "    aws_secret_access_key=creds['aws_access_secret_key']\n",
    ")\n",
    "glue = boto3.client(\n",
    "    'glue',\n",
    "    aws_access_key_id=creds['aws_access_key_id'],\n",
    "    aws_secret_access_key=creds['aws_access_secret_key']\n",
    ")\n",
    "s3 = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=creds['aws_access_key_id'],\n",
    "    aws_secret_access_key=creds['aws_access_secret_key']\n",
    ")\n",
    "iam = boto3.client(\n",
    "    'iam',\n",
    "    aws_access_key_id=creds['aws_access_key_id'],\n",
    "    aws_secret_access_key=creds['aws_access_secret_key']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ace21",
   "metadata": {},
   "source": [
    "## Step 0: IAM\n",
    "In order to run Glue processes, you need to create a specific IAM role with certain permissions. You can do this in the console, but for the sake of this tutorial, the role will be generated using the following blocks of code. First, the role needs to have a trust relationship that gives you access to Glue. That is set in the dictionary called `trust_relationship` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e5f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first create a IAM role\n",
    "trust_relationship = {\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": \"glue.amazonaws.com\"\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "glue_role = iam.create_role(\n",
    "    Path='/',\n",
    "    RoleName= IAM_GLUE_ROLE_NAME,\n",
    "    AssumeRolePolicyDocument=json.dumps(trust_relationship),\n",
    "    Description='Simple policy for interacting with Glue'\n",
    ")\n",
    "\n",
    "role_arn = glue_role['Role']['Arn']\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1497186",
   "metadata": {},
   "source": [
    "We also need to attach some policies to the role we created above. \n",
    "\n",
    "* AmazonS3FullAccess is a policy that gives the role access to reading and writing S3 objects.\n",
    "* AmazonAthenaFullAccess is a policy that gives the role full access to Amazon Athena.\n",
    "* AWSGlueConsoleSageMakerNotebookFullAccess is a policy that gives the role access to methods that interact with Glue and SageMaker.\n",
    "* AWSGlueConsoleFullAccess is a policy that gives the role access to Glue Console methods.\n",
    "* CloudWatchFullAccess is a policy that allows the role to access Cloud Watch results.\n",
    "* AWSCloudFormationReadOnlyAccess is a policy that allows the role to access Cloud Formation methods.\n",
    "\n",
    "We need all of these policies in order for this lab to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb599f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = [\n",
    "    'AmazonS3FullAccess',\n",
    "    'AmazonAthenaFullAccess',\n",
    "    'AWSGlueConsoleSageMakerNotebookFullAccess',\n",
    "    'AWSGlueConsoleFullAccess',\n",
    "    'CloudWatchFullAccess',\n",
    "    'AWSCloudFormationReadOnlyAccess'    \n",
    "]\n",
    "for policy in policies:\n",
    "    iam.attach_role_policy(\n",
    "        RoleName=IAM_GLUE_ROLE_NAME,\n",
    "        PolicyArn= f'arn:aws:iam::aws:policy/{policy}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6079f044",
   "metadata": {},
   "source": [
    "## Step 1A: S3\n",
    "\n",
    "We need to create a source for Glue to crawl and Athena to query. So create a bucket and upload a the file below by running the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ece56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let's create an S3 bucket upload the CSV file\n",
    "bucket = s3.Bucket(S3_BUCKET_NAME)\n",
    "bucket.create()\n",
    "\n",
    "filename = 'sin_cos.csv'\n",
    "with open(filename, 'rb') as data:\n",
    "    bucket.upload_fileobj(data, 'sin_cos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc49cc",
   "metadata": {},
   "source": [
    "## Step 2: Glue\n",
    "\n",
    "Now that we have the file loaded into S3, we will now process the data using Glue. To do that, we must first create a database and a crawler to read the data in S3.\n",
    "\n",
    "Let's first create the database using the `create_database` method with the `glue` client. There are two required parameters: the catalog id (which in this case is your AWS Account ID) and `DatabaseInput`, which is a dictionary that contains the name of the database you want to create. \n",
    "\n",
    "**Try It Out**: Run the code sample below to create a Glue database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb666246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now create a database using Glue\n",
    "database = glue.create_database(\n",
    "    CatalogId=ACCOUNT_ID,\n",
    "    DatabaseInput={\n",
    "        'Name': GLUE_DATABASE\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f20a0",
   "metadata": {},
   "source": [
    "Next, we will create a crawler using the `create_crawler` method using the `glue` client. It takes a couple of parameters. First it takes the name you want to assign to the crawler. You must also provide the ARN of the policy we created above. Additionally, you will need to provide the name of the database we just created. You will also provide targets, which are the places Glue will read to find data. For this example, we will simply provide S3 file paths for Glue to read. Also, we will provide a schema change policy and configuration parameters.\n",
    "\n",
    "**Note**: When supplying the S3 targets to Glue, the paths must be folders and not files.\n",
    "\n",
    "**Try It Out**: Run the code sample below to create a crawler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5571e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now crawl through the file uploaded to S3\n",
    "config = {\n",
    "    \"Version\" : 1.0,\n",
    "    \"CrawlerOutput\" : {\n",
    "        \"Partitions\" : {\n",
    "            \"AddOrUpdateBehavior\" : \"InheritFromTable\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "crawler = glue.create_crawler(\n",
    "    Name = GLUE_CRAWLER,\n",
    "    Role = role_arn,\n",
    "    DatabaseName = GLUE_DATABASE,\n",
    "    Targets = {\n",
    "        'S3Targets': [\n",
    "            {'Path': f's3://{S3_BUCKET_NAME}'}\n",
    "        ]\n",
    "    },\n",
    "    SchemaChangePolicy={\n",
    "        'UpdateBehavior': 'UPDATE_IN_DATABASE',\n",
    "        'DeleteBehavior': 'DELETE_FROM_DATABASE'\n",
    "    },\n",
    "    Configuration=json.dumps(config)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a414a058",
   "metadata": {},
   "source": [
    "Let's run the crawler we just created. To do this, you must use the `start_crawler` method providing the name of the crawler. To check on the crawler's status, use the `get_crawler` method, also providing the name of the crawler.\n",
    "\n",
    "**Try It Out**: Run the code block below. It will start the crawler you just created and check on its status every ten seconds. It will take roughly a minute for this code to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd677a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the crawler\n",
    "glue.start_crawler(\n",
    "    Name=GLUE_CRAWLER\n",
    ")\n",
    "\n",
    "#Check on the status of the crawler\n",
    "crawl_status = glue.get_crawler(\n",
    "    Name=GLUE_CRAWLER\n",
    ")\n",
    "\n",
    "while crawl_status['Crawler'].get('State') in ['RUNNING','STOPPING']:\n",
    "    print('Getting crawl status...')\n",
    "    time.sleep(10)\n",
    "    crawl_status = glue.get_crawler(\n",
    "        Name=GLUE_CRAWLER\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7665228e",
   "metadata": {},
   "source": [
    "Verify that your code ran correctly by running the block below. If not, then check your AWS credentials and other portions of the code for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see if crawler errored out in any way\n",
    "if crawl_status['Crawler'].get('LastCrawl',{}).get('ErrorMessage') != None:\n",
    "    print(\"There was an error in the crawling\")\n",
    "else:\n",
    "    print(\"Everything is okay.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077cb634",
   "metadata": {},
   "source": [
    "Because the crawler creates a table upon crawling the S3 buckets, we need to actually find the table created. The code block below usses the `get_tables` method and searches for a table with a `StorageDescriptor.Location` that contains the S3 bucket we created above. This should work since we just created the bucket. But if you used the bucket created in this lab for other Glue tables, then this might not work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for tables and grab table name\n",
    "glue_tables = glue.get_tables(\n",
    "    CatalogId=ACCOUNT_ID,\n",
    "    DatabaseName=GLUE_DATABASE\n",
    ")\n",
    "table_name = ''\n",
    "for table in glue_tables['TableList']:\n",
    "    if table.get('StorageDescriptor',{}).get('Location') == f's3://{S3_BUCKET_NAME}/':\n",
    "        table_name = table.get('Name')\n",
    "print(f'The table created by the crawler is named: {table_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fbf618",
   "metadata": {},
   "source": [
    "## Step 3: Athena\n",
    "\n",
    "Finally, we will query the data we crawled by using Athena. Simply call the `start_query_execution` method to query the data. The first argument you will provide is the `QueryString`, which is a SQL query. Secondly, you will provide a dictionary containing the name of the Glue database created above. Finally, you will then need to point the output of the query to an S3 bucket by using the `ResultConfiguration` parameter.\n",
    "\n",
    "After we start the query execution, we can get the status of the execution by using the `get_query_execution` method by retrieving the `QueryExecutionId` from the result of the `start_query_execution` method.\n",
    "\n",
    "**Try It Out**: Run the code block below in order to query the table the crawler created. Wait until the code block finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start a query execution\n",
    "query_data = athena.start_query_execution(\n",
    "    QueryString = f'SELECT COUNT(*), name FROM {table_name} GROUP BY name',\n",
    "    QueryExecutionContext = {\n",
    "        'Database': GLUE_DATABASE\n",
    "    }, \n",
    "    ResultConfiguration = {'OutputLocation': f's3://{S3_BUCKET_NAME}'}\n",
    ")\n",
    "\n",
    "#Get query execution data\n",
    "query_exec_results = athena.get_query_execution(\n",
    "    QueryExecutionId = query_data['QueryExecutionId']\n",
    ")\n",
    "while query_exec_results['QueryExecution']['Status'].get('State') in ['QUEUED','RUNNING']:\n",
    "    time.sleep(2)\n",
    "    print('Getting query execution')\n",
    "    query_exec_results = athena.get_query_execution(\n",
    "        QueryExecutionId = query_data['QueryExecutionId']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c31ac8",
   "metadata": {},
   "source": [
    "Now that the code block is finished executing, you can see the results by running the `get_query_results` method. You can also download the file object created from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f7fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get query results\n",
    "query_results = athena.get_query_results(\n",
    "    QueryExecutionId = query_data['QueryExecutionId']\n",
    ")\n",
    "\n",
    "query_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
